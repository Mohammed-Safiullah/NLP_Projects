{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "002a73ff",
      "metadata": {
        "id": "002a73ff"
      },
      "source": [
        "# TASK 5 Sentence 1\n",
        "Input sentence = 'He always spoke in grammatical sentences.'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c990bacc",
      "metadata": {
        "id": "c990bacc",
        "outputId": "d552ecdf-c834-44dc-d2c2-2c8ae7e364c5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\Razi\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#Importing the Required Libraries and wordnet\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import wordnet as wn # Importing wn as Wordnet\n",
        "nltk.download('wordnet')\n",
        "sentence = 'He always spoke in grammatical sentences.' #Input sentence for tokenization\n",
        "ambigious_word = 'sentences' # ambiguous word for wordnet synsets()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86a8aff6",
      "metadata": {
        "id": "86a8aff6",
        "outputId": "22ec92ee-aa56-4ec2-e419-2b03e09cdadd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['He', 'always', 'spoke', 'in', 'grammatical', 'sentences', '.']\n"
          ]
        }
      ],
      "source": [
        "tokenized_sentence = word_tokenize(sentence) #Tokenization of Input sentence\n",
        "print(tokenized_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb281bb8",
      "metadata": {
        "id": "bb281bb8",
        "outputId": "0cd5ed2d-1dff-4bfd-f3f9-6e63d7ca8d9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " The Pos tag of \"sentences\" is \"NNS\"\n"
          ]
        }
      ],
      "source": [
        "pos_sentence = pos_tag(tokenized_sentence) #Pos Tagging of the Input Sentence\n",
        "#print(pos_sentence)\n",
        "for word,pos in pos_sentence: #Iterating over POS_SENTENCE\n",
        "    if ambigious_word == word:\n",
        "        print(f' The Pos tag of \"{word}\" is \"{pos}\"') #Printing Ambiguous word and its POS TAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbb389e6",
      "metadata": {
        "id": "bbb389e6",
        "outputId": "cc9e75c6-9e0a-4686-a37a-6478f3d30d16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sentence.n.01 n a string of words satisfying the grammatical rules of a language\n",
            "conviction.n.02 n (criminal law) a final judgment of guilty in a criminal case and the punishment that is imposed\n",
            "prison_term.n.01 n the period of time a prisoner is imprisoned\n"
          ]
        }
      ],
      "source": [
        "synsets = wn.synsets(ambigious_word) #Looking for Synsets of the ambiguous word in the wordnet\n",
        "\n",
        "for synset in synsets: #iterating over synsets\n",
        "    if synset.pos()=='n': # if the synsets pos are noun, printing name, its pos tag and its definition\n",
        "        print(synset.name(), synset.pos(), synset.definition())\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c305402",
      "metadata": {
        "id": "1c305402"
      },
      "source": [
        "#  TASK 5 Sentence 2\n",
        "Input sentence = 'The court will sentence the offender tomorrow.'\n",
        "All the comments for the code below are almost the same as Sentence 1, only few are updated as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5da5cf6d",
      "metadata": {
        "id": "5da5cf6d",
        "outputId": "8a8e1014-9c69-45bf-c68b-23ced0cc48f8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\Razi\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import wordnet as wn\n",
        "nltk.download('wordnet')\n",
        "sentence = 'The court will sentence the offender tomorrow.'\n",
        "ambigious_word = 'sentence'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "883526ff",
      "metadata": {
        "id": "883526ff",
        "outputId": "34784e82-401d-4644-a353-e62da047fb1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['The', 'court', 'will', 'sentence', 'the', 'offender', 'tomorrow', '.']\n"
          ]
        }
      ],
      "source": [
        "tokenized_sentence = word_tokenize(sentence)\n",
        "print(tokenized_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0684d59",
      "metadata": {
        "id": "d0684d59",
        "outputId": "5063446e-55a1-44d7-ff64-3b510096f4c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " The Pos tag of \"sentence\" is \"VB\"\n"
          ]
        }
      ],
      "source": [
        "pos_sentence = pos_tag(tokenized_sentence)\n",
        "#print(pos_sentence)\n",
        "\n",
        "for word,pos in pos_sentence:\n",
        "    if ambigious_word == word:\n",
        "        print(f' The Pos tag of \"{word}\" is \"{pos}\"')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7ea1619",
      "metadata": {
        "id": "d7ea1619",
        "outputId": "536eca8b-3a52-4c12-ae32-a93b96af4197"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sentence.v.01 v pronounce a sentence on (somebody) in a court of law\n"
          ]
        }
      ],
      "source": [
        "synsets = wn.synsets(ambigious_word)\n",
        "\n",
        "for synset in synsets:\n",
        "    if synset.pos()=='v': #if the pos of the synsets are Verb, printing its name, pos, and definition\n",
        "        print(synset.name(), synset.pos(), synset.definition())\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ee676d4",
      "metadata": {
        "id": "1ee676d4"
      },
      "source": [
        "# TASK 5 Sentence 3\n",
        "input Sentence = 'A clock shows the time of the day.'\n",
        "Comments are same as the Sentence 1, only few are updated as needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e5ec0d7",
      "metadata": {
        "id": "3e5ec0d7",
        "outputId": "20b195ee-41f2-40e2-b3ea-7574039f8e25"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\Razi\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import wordnet as wn\n",
        "nltk.download('wordnet')\n",
        "sentence = 'A clock shows the time of the day.'\n",
        "ambigious_word = 'clock'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6219681b",
      "metadata": {
        "id": "6219681b",
        "outputId": "a772b402-9e1d-442c-ee12-6e5b25c4cc2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['A', 'clock', 'shows', 'the', 'time', 'of', 'the', 'day', '.']\n"
          ]
        }
      ],
      "source": [
        "tokenized_sentence = word_tokenize(sentence)\n",
        "print(tokenized_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9261a0b",
      "metadata": {
        "id": "a9261a0b",
        "outputId": "d55f0e05-bf6d-47f8-f6c7-688d8b3b76a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " The Pos tag of \"clock\" is \"NN\"\n"
          ]
        }
      ],
      "source": [
        "pos_sentence = pos_tag(tokenized_sentence)\n",
        "#print(pos_sentence)\n",
        "\n",
        "for word,pos in pos_sentence:\n",
        "    if ambigious_word == word:\n",
        "        print(f' The Pos tag of \"{word}\" is \"{pos}\"')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da3a00d8",
      "metadata": {
        "id": "da3a00d8",
        "outputId": "01dc6b35-814d-4ecd-af92-da00bce8178f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "clock.n.01 n a timepiece that shows the time of day\n"
          ]
        }
      ],
      "source": [
        "synsets = wn.synsets(ambigious_word)\n",
        "\n",
        "for synset in synsets:\n",
        "    if synset.pos()=='n': #if the synset pos is noun, printing its name, pos and definition\n",
        "        print(synset.name(), synset.pos(), synset.definition())\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "461099a0",
      "metadata": {
        "id": "461099a0"
      },
      "source": [
        "# TASK 5 Sentence 4\n",
        "Input Sentence = 'The manager will clock the runners tomorrow.'\n",
        "Comments are same as Sentence 1, only few are updated as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ace5f8b6",
      "metadata": {
        "id": "ace5f8b6",
        "outputId": "7ac7b54f-fafe-48ca-cdbe-8dbdd7ca4c4a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\Razi\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import wordnet as wn\n",
        "nltk.download('wordnet')\n",
        "sentence = 'The manager will clock the runners tomorrow.'\n",
        "ambigious_word = 'clock'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f396c5b4",
      "metadata": {
        "id": "f396c5b4",
        "outputId": "64ee0104-01d2-4157-86c1-48ac266bc1ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['The', 'manager', 'will', 'clock', 'the', 'runners', 'tomorrow', '.']\n"
          ]
        }
      ],
      "source": [
        "tokenized_sentence = word_tokenize(sentence)\n",
        "print(tokenized_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c428e2c",
      "metadata": {
        "id": "5c428e2c",
        "outputId": "59ca0377-181d-4078-bc50-29b453020e88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " The Pos tag of \"clock\" is \"VB\"\n"
          ]
        }
      ],
      "source": [
        "pos_sentence = pos_tag(tokenized_sentence)\n",
        "#print(pos_sentence)\n",
        "\n",
        "for word,pos in pos_sentence:\n",
        "    if ambigious_word == word:\n",
        "        print(f' The Pos tag of \"{word}\" is \"{pos}\"')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "241f9ea5",
      "metadata": {
        "id": "241f9ea5",
        "outputId": "691a802b-822c-4181-b952-059430fc0d80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "clock.v.01 v measure the time or duration of an event or action or the person who performs an action in a certain period of time\n"
          ]
        }
      ],
      "source": [
        "synsets = wn.synsets(ambigious_word)\n",
        "\n",
        "for synset in synsets:\n",
        "    if synset.pos()=='v': #if the synset pos if Verb, printing its name, its pos and definition.\n",
        "        print(synset.name(), synset.pos(), synset.definition())\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25026b27",
      "metadata": {
        "id": "25026b27"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}